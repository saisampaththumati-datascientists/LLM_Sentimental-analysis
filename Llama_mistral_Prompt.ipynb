{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "gpuType": "V28",
      "authorship_tag": "ABX9TyPeUFAsR4+YickCsGzvMpNu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c1c716184ca48968269ba710e50a31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_500ff92ca7434fd0a4621f086b60f1f8",
              "IPY_MODEL_fc493f5b70404a1eaf18ce0742013724",
              "IPY_MODEL_cadcad0248ce4e0888101bb09174b8f3"
            ],
            "layout": "IPY_MODEL_d1375da1f8d642f59e270eb720dd6dc3"
          }
        },
        "500ff92ca7434fd0a4621f086b60f1f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c0c13b467f64557bdc01fda6abbf765",
            "placeholder": "​",
            "style": "IPY_MODEL_47fd65c5918442b9b84138a76846323f",
            "value": "llama-2-7b-chat.Q8_0.gguf: 100%"
          }
        },
        "fc493f5b70404a1eaf18ce0742013724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e105c23b29f1429d879bd19f467e847e",
            "max": 7161089728,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05ff4a2d10954993b89fd6bf311c3f4d",
            "value": 7161089728
          }
        },
        "cadcad0248ce4e0888101bb09174b8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c38a69f11134e7986bbb18e2a75ad36",
            "placeholder": "​",
            "style": "IPY_MODEL_fd148112a96c496faf6c458fa091865c",
            "value": " 7.16G/7.16G [00:20&lt;00:00, 312MB/s]"
          }
        },
        "d1375da1f8d642f59e270eb720dd6dc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c0c13b467f64557bdc01fda6abbf765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47fd65c5918442b9b84138a76846323f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e105c23b29f1429d879bd19f467e847e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ff4a2d10954993b89fd6bf311c3f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c38a69f11134e7986bbb18e2a75ad36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd148112a96c496faf6c458fa091865c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saisampaththumati-datascientists/LLM_Sentimental-analysis/blob/main/Llama_mistral_Prompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLama Model practicing the Promt enginnering\n",
        "-  LLaMA2\n",
        "- install llama-cpp-python"
      ],
      "metadata": {
        "id": "iOh5ADNaqRcr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npDuUCNkpxBM",
        "outputId": "14719db2-0edf-4c48-a201-43f9c60caac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.82.tar.gz (50.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.82-cp310-cp310-linux_x86_64.whl size=2812503 sha256=5e05b28a6bd135849d197f1adba92c47d96d5e2ef7e62166b1d77755458b283d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/da/5a/272c969ba31c678e6bee2543f3be4dfa67d0feb36ed6f94c01\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.82\n"
          ]
        }
      ],
      "source": [
        "pip install llama-cpp-python"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## installing the llama cpp Python model in the system\n",
        "## Install hugging Face hub"
      ],
      "metadata": {
        "id": "Rc3Zp-bxqyEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-zx658BrI75",
        "outputId": "e8cb24c0-289c-46c4-fca7-eb55e58dc8b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import the hf_hub download from huggingface\n",
        "- import llama from llama_cpp"
      ],
      "metadata": {
        "id": "1dGlfUqfrbQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama"
      ],
      "metadata": {
        "id": "nloO6nasr8aC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Llama\n",
        "- what are the steps ?\n",
        "- Take the name or path of the model\n",
        "- Take base_model\n",
        "- Pass the parameter in the variable name model_path\n"
      ],
      "metadata": {
        "id": "Q7pWEnhFsHZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name_path =\"TheBloke/Llama-2-7B-Chat-GGUF\"\n",
        "base_model=\"llama-2-7b-chat.Q8_0.gguf\""
      ],
      "metadata": {
        "id": "jn64LSQ4sMbk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the hf_hub_download  to download the modell\n",
        "model_path= hf_hub_download(repo_id=Model_name_path,filename=base_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "6c1c716184ca48968269ba710e50a31f",
            "500ff92ca7434fd0a4621f086b60f1f8",
            "fc493f5b70404a1eaf18ce0742013724",
            "cadcad0248ce4e0888101bb09174b8f3",
            "d1375da1f8d642f59e270eb720dd6dc3",
            "1c0c13b467f64557bdc01fda6abbf765",
            "47fd65c5918442b9b84138a76846323f",
            "e105c23b29f1429d879bd19f467e847e",
            "05ff4a2d10954993b89fd6bf311c3f4d",
            "2c38a69f11134e7986bbb18e2a75ad36",
            "fd148112a96c496faf6c458fa091865c"
          ]
        },
        "id": "9MiT3Bb3tn_B",
        "outputId": "b6e0bb3b-eaaf-4192-ab88-354dc5d11a0b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llama-2-7b-chat.Q8_0.gguf:   0%|          | 0.00/7.16G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c1c716184ca48968269ba710e50a31f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nC3xu5cuCsG",
        "outputId": "dd5bd9a1-c625-451c-c36c-fecdb55afcf5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lccp_llm=Llama(model_path=model_path,\n",
        "               n_batch=512,\n",
        "               n_gpu_layers=32\n",
        "               ,n_ctx=4096,\n",
        "               n_threads=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA7jXc_durPD",
        "outputId": "5129ed9a-53fa-49aa-c255-ff9f851baade"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /root/.cache/huggingface/hub/models--TheBloke--Llama-2-7B-Chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q8_0.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 7\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q8_0:  226 tensors\n",
            "llm_load_vocab: special tokens cache size = 259\n",
            "llm_load_vocab: token to piece cache size = 0.1684 MB\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q8_0\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 6.67 GiB (8.50 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_print_meta: max token length = 48\n",
            "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
            "llm_load_tensors:        CPU buffer size =  6828.64 MiB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 4096\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =  2048.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 2048.00 MiB, K (f16): 1024.00 MiB, V (f16): 1024.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =   296.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 0 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '7'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lccp_llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlZT5ykwvu5d",
        "outputId": "224b4817-48f0-49a1-a5ef-25b1b6103e0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<llama_cpp.llama.Llama at 0x7efe6b109300>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now first step system_message Need to create the system_message\n",
        "system_message = \"\"\"You are an assistance you are answer a quary on a finacial information\n",
        "Donot reapeat the question only answer the question presented by the user\"\"\""
      ],
      "metadata": {
        "id": "9bFraFSLv8zy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the answer template how the answer need to be given to the user\n",
        "answer_template = \"\"\"\n",
        "Context:\n",
        "{context}\n",
        "===\n",
        "Using the context above generated {num_answer} distinct answer to the following quary Question\n",
        "{qustion}.\n",
        "Arrange your answer in thew bullet point.\n",
        "present answer in the bullet points.\"\"\""
      ],
      "metadata": {
        "id": "boNxMHBbw_hi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AXA_2000_context =\"\"\"\n",
        "As soon as he takes office, Henri de Castries chooses to sell off the US investment bank Donaldson, Lufkin & Jenrette (DLJ) and target operational excellence for the Group’s core business areas (insurance and asset management).\n",
        "\n",
        "The Group organizes itself to weather this storm: rolling out a plan to reduce spending, turning around its technical results and further strengthening its risk management, with the creation of Group Risk Management which objective is to analyze the Group’s risk exposure and appetite with a more in-depth approach and to prepare for future new regulations (Solvency 2).\n",
        "\n",
        "In 2006, the economic environment is positive again. AXA returns to profitable growth, acquires the Swiss firm Winterthur and starts investing in emerging markets.\n",
        "\n",
        "When the subprime financial crisis breaks out in summer 2007, AXA has learned the lessons from 2001. Thanks to its efficient internal risk management system (GRM), the Group is affected, but shows its resilience, without public bailouts.\n",
        "\n",
        "In this volatile environment, AXA remains convinced of the importance of its long-term commitments to its customers and society in general. In line with this spirit, AXA launches the AXA Research Fund to improve the understanding and prevention of major risks around the world. The AXA Research Fund further enhances the wide range of initiatives in place across the Group, which is committed to taking action on what counts for communities. Created out of the belief that science has a key role to play in meeting society’s major challenges, AXA sets out its commitment to help drive collective progress by supporting research projects focused on health, the environment, new technologies and socioeconomics.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "m5WF8oeNyao5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_question = \"When the subprime financial crisis breaks out? What the company had learned?\""
      ],
      "metadata": {
        "id": "-WOOrM-UyxfW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Template\n",
        "- llama_prompt_template has the base template That is written in the certain pattern\n",
        "- `Ins` is the instruction\n",
        "- `<<sys>>` is start of the system message\n",
        "- `{system}` is the template driven where we are passing the certain instructions\n",
        "- `{user_message}` It is template driven where it is passed certain Instruction"
      ],
      "metadata": {
        "id": "UcsR7AWq4WuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llama_prompt_template='''[/s][INS]<<SYS>>\n",
        "{system_message}\n",
        "<</SYS>>\n",
        "{user_message}[/INST]'''"
      ],
      "metadata": {
        "id": "RymYBibzyyBK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self-consistency\n",
        "- In the Self-Consistency the we generate number of answer(num_answer=3)  for a single question. with this the model will pick most occurance answer across the occurrences."
      ],
      "metadata": {
        "id": "-GI6EZQGtrUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_prompt=llama_prompt_template.format(\n",
        "    system_message=system_message,\n",
        "    user_message=answer_template.format(\n",
        "        context=AXA_2000_context,\n",
        "        qustion=actual_question,\n",
        "        num_answer=3\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "vnk7-GSKzqKZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_prompt"
      ],
      "metadata": {
        "id": "kKfbEvDz054X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "5bffe4ee-0e12-4319-9f63-54ea71e7bd4c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[/s][INS]<<SYS>>\\nYou are an assistance you are answer a quary on a finacial information\\nDonot reapeat the question only answer the question presented by the user\\n<</SYS>>\\n\\nContext:\\n\\nAs soon as he takes office, Henri de Castries chooses to sell off the US investment bank Donaldson, Lufkin & Jenrette (DLJ) and target operational excellence for the Group’s core business areas (insurance and asset management).\\n\\nThe Group organizes itself to weather this storm: rolling out a plan to reduce spending, turning around its technical results and further strengthening its risk management, with the creation of Group Risk Management which objective is to analyze the Group’s risk exposure and appetite with a more in-depth approach and to prepare for future new regulations (Solvency 2).\\n\\nIn 2006, the economic environment is positive again. AXA returns to profitable growth, acquires the Swiss firm Winterthur and starts investing in emerging markets.\\n\\nWhen the subprime financial crisis breaks out in summer 2007, AXA has learned the lessons from 2001. Thanks to its efficient internal risk management system (GRM), the Group is affected, but shows its resilience, without public bailouts.\\n\\nIn this volatile environment, AXA remains convinced of the importance of its long-term commitments to its customers and society in general. In line with this spirit, AXA launches the AXA Research Fund to improve the understanding and prevention of major risks around the world. The AXA Research Fund further enhances the wide range of initiatives in place across the Group, which is committed to taking action on what counts for communities. Created out of the belief that science has a key role to play in meeting society’s major challenges, AXA sets out its commitment to help drive collective progress by supporting research projects focused on health, the environment, new technologies and socioeconomics.\\n\\n===\\nUsing the context above generated 3 distinct answer to the following quary Question\\nWhen the subprime financial crisis breaks out? What the company had learned?.\\nArrange your answer in thew bullet point.\\npresent answer in the bullet points.[/INST]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_TwzBp_nl8m",
        "outputId": "a6c78c16-0782-4098-9ee0-2aa2d6840cfd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[/s][INS]<<SYS>>\n",
            "You are an assistance you are answer a quary on a finacial information\n",
            "Donot reapeat the question only answer the question presented by the user\n",
            "<</SYS>>\n",
            "\n",
            "Context:\n",
            "\n",
            "As soon as he takes office, Henri de Castries chooses to sell off the US investment bank Donaldson, Lufkin & Jenrette (DLJ) and target operational excellence for the Group’s core business areas (insurance and asset management).\n",
            "\n",
            "The Group organizes itself to weather this storm: rolling out a plan to reduce spending, turning around its technical results and further strengthening its risk management, with the creation of Group Risk Management which objective is to analyze the Group’s risk exposure and appetite with a more in-depth approach and to prepare for future new regulations (Solvency 2).\n",
            "\n",
            "In 2006, the economic environment is positive again. AXA returns to profitable growth, acquires the Swiss firm Winterthur and starts investing in emerging markets.\n",
            "\n",
            "When the subprime financial crisis breaks out in summer 2007, AXA has learned the lessons from 2001. Thanks to its efficient internal risk management system (GRM), the Group is affected, but shows its resilience, without public bailouts.\n",
            "\n",
            "In this volatile environment, AXA remains convinced of the importance of its long-term commitments to its customers and society in general. In line with this spirit, AXA launches the AXA Research Fund to improve the understanding and prevention of major risks around the world. The AXA Research Fund further enhances the wide range of initiatives in place across the Group, which is committed to taking action on what counts for communities. Created out of the belief that science has a key role to play in meeting society’s major challenges, AXA sets out its commitment to help drive collective progress by supporting research projects focused on health, the environment, new technologies and socioeconomics.\n",
            "\n",
            "===\n",
            "Using the context above generated 3 distinct answer to the following quary Question\n",
            "When the subprime financial crisis breaks out? What the company had learned?.\n",
            "Arrange your answer in thew bullet point.\n",
            "present answer in the bullet points.[/INST]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer_promt = llama_prompt_template.format(\n",
        "    system_message=system_message,\n",
        "    user_message=answer_template.format(\n",
        "      context=AXA_2000_context,\n",
        "      num_answer=4,\n",
        "      qustion=actual_question\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "bhN_fonOnpBb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_promt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "k3Ph-lr9pEP7",
        "outputId": "13428249-b86b-44f2-a2bf-7633c8f36dfe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[/s][INS]<<SYS>>\\nYou are an assistance you are answer a quary on a finacial information\\nDonot reapeat the question only answer the question presented by the user\\n<</SYS>>\\n\\nContext:\\n\\nAs soon as he takes office, Henri de Castries chooses to sell off the US investment bank Donaldson, Lufkin & Jenrette (DLJ) and target operational excellence for the Group’s core business areas (insurance and asset management).\\n\\nThe Group organizes itself to weather this storm: rolling out a plan to reduce spending, turning around its technical results and further strengthening its risk management, with the creation of Group Risk Management which objective is to analyze the Group’s risk exposure and appetite with a more in-depth approach and to prepare for future new regulations (Solvency 2).\\n\\nIn 2006, the economic environment is positive again. AXA returns to profitable growth, acquires the Swiss firm Winterthur and starts investing in emerging markets.\\n\\nWhen the subprime financial crisis breaks out in summer 2007, AXA has learned the lessons from 2001. Thanks to its efficient internal risk management system (GRM), the Group is affected, but shows its resilience, without public bailouts.\\n\\nIn this volatile environment, AXA remains convinced of the importance of its long-term commitments to its customers and society in general. In line with this spirit, AXA launches the AXA Research Fund to improve the understanding and prevention of major risks around the world. The AXA Research Fund further enhances the wide range of initiatives in place across the Group, which is committed to taking action on what counts for communities. Created out of the belief that science has a key role to play in meeting society’s major challenges, AXA sets out its commitment to help drive collective progress by supporting research projects focused on health, the environment, new technologies and socioeconomics.\\n\\n===\\nUsing the context above generated 4 distinct answer to the following quary Question\\nWhen the subprime financial crisis breaks out? What the company had learned?.\\nArrange your answer in thew bullet point.\\npresent answer in the bullet points.[/INST]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer_promt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_-WN9kApFmf",
        "outputId": "6726ead2-38af-4303-e6c5-1b690be1a922"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[/s][INS]<<SYS>>\n",
            "You are an assistance you are answer a quary on a finacial information\n",
            "Donot reapeat the question only answer the question presented by the user\n",
            "<</SYS>>\n",
            "\n",
            "Context:\n",
            "\n",
            "As soon as he takes office, Henri de Castries chooses to sell off the US investment bank Donaldson, Lufkin & Jenrette (DLJ) and target operational excellence for the Group’s core business areas (insurance and asset management).\n",
            "\n",
            "The Group organizes itself to weather this storm: rolling out a plan to reduce spending, turning around its technical results and further strengthening its risk management, with the creation of Group Risk Management which objective is to analyze the Group’s risk exposure and appetite with a more in-depth approach and to prepare for future new regulations (Solvency 2).\n",
            "\n",
            "In 2006, the economic environment is positive again. AXA returns to profitable growth, acquires the Swiss firm Winterthur and starts investing in emerging markets.\n",
            "\n",
            "When the subprime financial crisis breaks out in summer 2007, AXA has learned the lessons from 2001. Thanks to its efficient internal risk management system (GRM), the Group is affected, but shows its resilience, without public bailouts.\n",
            "\n",
            "In this volatile environment, AXA remains convinced of the importance of its long-term commitments to its customers and society in general. In line with this spirit, AXA launches the AXA Research Fund to improve the understanding and prevention of major risks around the world. The AXA Research Fund further enhances the wide range of initiatives in place across the Group, which is committed to taking action on what counts for communities. Created out of the belief that science has a key role to play in meeting society’s major challenges, AXA sets out its commitment to help drive collective progress by supporting research projects focused on health, the environment, new technologies and socioeconomics.\n",
            "\n",
            "===\n",
            "Using the context above generated 4 distinct answer to the following quary Question\n",
            "When the subprime financial crisis breaks out? What the company had learned?.\n",
            "Arrange your answer in thew bullet point.\n",
            "present answer in the bullet points.[/INST]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=lccp_llm(prompt=answer_promt,max_tokens=1500,temperature=0.2,top_p=0.2,min_p=0.05\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soHPibKgpGtf",
        "outputId": "62f21916-ddff-419c-b248-02b69f66d182"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =   35527.80 ms\n",
            "llama_print_timings:      sample time =      36.11 ms /   180 runs   (    0.20 ms per token,  4984.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =   35526.78 ms /   509 tokens (   69.80 ms per token,    14.33 tokens per second)\n",
            "llama_print_timings:        eval time =   56982.90 ms /   179 runs   (  318.34 ms per token,     3.14 tokens per second)\n",
            "llama_print_timings:       total time =   92678.07 ms /   688 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oPmskgoplt0",
        "outputId": "4044680d-8b06-43c3-f9e8-c003d87bf1a8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-78634b4b-556e-44aa-8247-e29f0575ac95', 'object': 'text_completion', 'created': 1721178191, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-7B-Chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '  When the subprime financial crisis broke out in summer 2007, AXA had learned several important lessons from its previous experience in 2001:\\n• Efficient internal risk management system (GRM): AXA had developed a robust risk management system, which helped it to weather the crisis without public bailouts.\\n• Resilience: Despite being affected by the crisis, AXA demonstrated its resilience and ability to adapt to challenging situations.\\n• Long-term commitments: AXA remained committed to its long-term commitments to its customers and society in general, even during times of economic uncertainty.\\n• Importance of research: AXA recognized the importance of investing in research to improve understanding and prevention of major risks around the world, launching the AXA Research Fund.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 509, 'completion_tokens': 179, 'total_tokens': 688}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "factual_answer= response[\"choices\"][0]['text']\n",
        "print(factual_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqSoHNYlqGdF",
        "outputId": "bd44f97e-d258-4933-dc39-3c9002ea33a2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  When the subprime financial crisis broke out in summer 2007, AXA had learned several important lessons from its previous experience in 2001:\n",
            "• Efficient internal risk management system (GRM): AXA had developed a robust risk management system, which helped it to weather the crisis without public bailouts.\n",
            "• Resilience: Despite being affected by the crisis, AXA demonstrated its resilience and ability to adapt to challenging situations.\n",
            "• Long-term commitments: AXA remained committed to its long-term commitments to its customers and society in general, even during times of economic uncertainty.\n",
            "• Importance of research: AXA recognized the importance of investing in research to improve understanding and prevention of major risks around the world, launching the AXA Research Fund.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "consistancy_template = \"\"\"\n",
        "Here are {num_answer} answer for the question mention below:\n",
        "Question:\n",
        "{question}\n",
        "Answer:\n",
        "{Answer}\n",
        "Observe the answers mentioned above and choose the answer that occurs most.\n",
        "Present only the most frequent solution in the following format.\n",
        "Final Answer:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rqBOEU8MqgLK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "consistancy_prompt= llama_prompt_template.format(\n",
        "    system_message=system_message,\n",
        "    user_message=consistancy_template.format(\n",
        "        num_answer=4,\n",
        "        question=actual_question,\n",
        "        Answer=factual_answer\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "RsPvWb6XrXNB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response= lccp_llm(prompt=consistancy_prompt,temperature=0.2,echo=False,top_p=0.80,min_p=0.09,max_tokens=1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-HHGP8IrmH_",
        "outputId": "5e7af22c-9773-4b26-e091-d762117ffdb3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =   35527.80 ms\n",
            "llama_print_timings:      sample time =      14.80 ms /    70 runs   (    0.21 ms per token,  4731.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =   17524.69 ms /   250 tokens (   70.10 ms per token,    14.27 tokens per second)\n",
            "llama_print_timings:        eval time =   22168.09 ms /    69 runs   (  321.28 ms per token,     3.11 tokens per second)\n",
            "llama_print_timings:       total time =   39757.53 ms /   319 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpD4mJN2s_0R",
        "outputId": "989ae08e-0bb7-4a41-b207-8ad43c77850b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'cmpl-c127770e-48bc-463c-8b31-203be318d48f',\n",
              " 'object': 'text_completion',\n",
              " 'created': 1721178283,\n",
              " 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-7B-Chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q8_0.gguf',\n",
              " 'choices': [{'text': '  Final Answer: When the subprime financial crisis broke out in summer 2007, AXA had learned several important lessons from its previous experience in 2001, including the importance of efficient internal risk management system (GRM), resilience, long-term commitments, and the importance of research.',\n",
              "   'index': 0,\n",
              "   'logprobs': None,\n",
              "   'finish_reason': 'stop'}],\n",
              " 'usage': {'prompt_tokens': 303, 'completion_tokens': 69, 'total_tokens': 372}}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Response with Self-consistency"
      ],
      "metadata": {
        "id": "JR8_dWId4ETU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtWGpdljtCCX",
        "outputId": "5360fe1b-53fc-43d9-d16f-66d0857d94f3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-c127770e-48bc-463c-8b31-203be318d48f', 'object': 'text_completion', 'created': 1721178283, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-7B-Chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '  Final Answer: When the subprime financial crisis broke out in summer 2007, AXA had learned several important lessons from its previous experience in 2001, including the importance of efficient internal risk management system (GRM), resilience, long-term commitments, and the importance of research.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 303, 'completion_tokens': 69, 'total_tokens': 372}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2x_YLoZtEYH",
        "outputId": "fa223fd3-832d-40ba-d7e6-9fb4e54bf166"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Final Answer: When the subprime financial crisis broke out in summer 2007, AXA had learned several important lessons from its previous experience in 2001, including the importance of efficient internal risk management system (GRM), resilience, long-term commitments, and the importance of research.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tree-of-Thought\n",
        "- In the Tree of the facts the we will generate answers n_number=3 and with the percentage/ rank score will give the best answer"
      ],
      "metadata": {
        "id": "KZEOM2wluwap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "solution_template =\"\"\"\n",
        "Generate {number_answer} answer for the following question\n",
        "\n",
        "problem:\n",
        "{problem}\n",
        "consider the following factor compute the following answer\n",
        "factor:\n",
        "{factors}\n",
        "Present the solutions in numbered bullet points. Present only the solutions.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "XvtQfYZ3tU-w"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "factors=\"\"\"\n",
        "1.Risk appetite\n",
        "2.Risk culture\n",
        "3.Risk governance\n",
        "4.Compliance\n",
        "5.Risk mitigation\n",
        "6.Risk identification\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "HBWXadUnwT-0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_of_thoughts= llama_prompt_template.format(\n",
        "    system_message=system_message,\n",
        "    user_message=solution_template.format(\n",
        "        number_answer=3,\n",
        "        problem=AXA_2000_context,\n",
        "        factors=factors,\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "qvZwYAD0vwMA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = lccp_llm(prompt=tree_of_thoughts,echo=False,max_tokens=1500,frequency_penalty=0.2,top_p=.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j--sAhF8w5hz",
        "outputId": "bd736082-b792-4434-ef68-db811f69f18e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =   35527.80 ms\n",
            "llama_print_timings:      sample time =      50.81 ms /   254 runs   (    0.20 ms per token,  4998.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =   35785.58 ms /   488 tokens (   73.33 ms per token,    13.64 tokens per second)\n",
            "llama_print_timings:        eval time =   80535.94 ms /   253 runs   (  318.32 ms per token,     3.14 tokens per second)\n",
            "llama_print_timings:       total time =  116575.71 ms /   741 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygnMCmGYxjek",
        "outputId": "16dade62-8bc5-412b-ebfd-50bccfa97060"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Based on the provided information, here are the solutions for each of the factors mentioned:\n",
            "1. Risk Appetite:\n",
            "* AXA has a clear and well-defined risk appetite that is aligned with its business strategy and objectives.\n",
            "2. Risk Culture:\n",
            "* AXA has a strong risk culture that encourages employees to speak up and report potential risks, promoting a proactive approach to risk management.\n",
            "3. Risk Governance:\n",
            "* AXA has an effective risk governance structure in place, with clear roles and responsibilities for risk management across the organization.\n",
            "4. Compliance:\n",
            "* AXA places a high priority on compliance and adheres to all relevant laws and regulations, including Solvency 2.\n",
            "5. Risk Mitigation:\n",
            "* AXA has implemented various risk mitigation strategies, such as diversification of its investment portfolio and the creation of Group Risk Management, to minimize potential risks.\n",
            "6. Risk Identification:\n",
            "* AXA has a robust risk identification process in place, regularly identifying and assessing potential risks to the organization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "solution_response=response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "IQErOjGozHZi"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_template = \"\"\"\n",
        "For the following problem: {problem}, evaluate each solution in the following proposed solutions: \\n{solutions}\\n.\n",
        "\n",
        "Analyze pros, cons, feasibility, and probability of success for each solution.\n",
        "Present your evaluations of each solutions.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "dzYZl5Y-xo92"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evalution_prompt= llama_prompt_template.format(\n",
        "    system_message=system_message,\n",
        "    user_message=evaluation_template.format(\n",
        "        problem=AXA_2000_context,\n",
        "        solutions=solution_response,\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "UT9n_UaUywpO"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evalution_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkaqnR16zPpL",
        "outputId": "8818766d-f5c8-4af0-98e4-efe02f0661e1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[/s][INS]<<SYS>>\n",
            "You are an assistance you are answer a quary on a finacial information\n",
            "Donot reapeat the question only answer the question presented by the user\n",
            "<</SYS>>\n",
            "\n",
            "For the following problem: \n",
            "As soon as he takes office, Henri de Castries chooses to sell off the US investment bank Donaldson, Lufkin & Jenrette (DLJ) and target operational excellence for the Group’s core business areas (insurance and asset management).\n",
            "\n",
            "The Group organizes itself to weather this storm: rolling out a plan to reduce spending, turning around its technical results and further strengthening its risk management, with the creation of Group Risk Management which objective is to analyze the Group’s risk exposure and appetite with a more in-depth approach and to prepare for future new regulations (Solvency 2).\n",
            "\n",
            "In 2006, the economic environment is positive again. AXA returns to profitable growth, acquires the Swiss firm Winterthur and starts investing in emerging markets.\n",
            "\n",
            "When the subprime financial crisis breaks out in summer 2007, AXA has learned the lessons from 2001. Thanks to its efficient internal risk management system (GRM), the Group is affected, but shows its resilience, without public bailouts.\n",
            "\n",
            "In this volatile environment, AXA remains convinced of the importance of its long-term commitments to its customers and society in general. In line with this spirit, AXA launches the AXA Research Fund to improve the understanding and prevention of major risks around the world. The AXA Research Fund further enhances the wide range of initiatives in place across the Group, which is committed to taking action on what counts for communities. Created out of the belief that science has a key role to play in meeting society’s major challenges, AXA sets out its commitment to help drive collective progress by supporting research projects focused on health, the environment, new technologies and socioeconomics.\n",
            ", evaluate each solution in the following proposed solutions: \n",
            "  Based on the provided information, here are the solutions for each of the factors mentioned:\n",
            "1. Risk Appetite:\n",
            "* AXA has a clear and well-defined risk appetite that is aligned with its business strategy and objectives.\n",
            "2. Risk Culture:\n",
            "* AXA has a strong risk culture that encourages employees to speak up and report potential risks, promoting a proactive approach to risk management.\n",
            "3. Risk Governance:\n",
            "* AXA has an effective risk governance structure in place, with clear roles and responsibilities for risk management across the organization.\n",
            "4. Compliance:\n",
            "* AXA places a high priority on compliance and adheres to all relevant laws and regulations, including Solvency 2.\n",
            "5. Risk Mitigation:\n",
            "* AXA has implemented various risk mitigation strategies, such as diversification of its investment portfolio and the creation of Group Risk Management, to minimize potential risks.\n",
            "6. Risk Identification:\n",
            "* AXA has a robust risk identification process in place, regularly identifying and assessing potential risks to the organization.\n",
            ".\n",
            "\n",
            "Analyze pros, cons, feasibility, and probability of success for each solution.\n",
            "Present your evaluations of each solutions.\n",
            "[/INST]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response= lccp_llm(prompt=evalution_prompt,temperature=0.5,top_p=0.8,max_tokens=1500,echo=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bcp7hYL8zY6N",
        "outputId": "bb838bea-9277-422e-8300-10092543d496"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =   35527.80 ms\n",
            "llama_print_timings:      sample time =     115.05 ms /   568 runs   (    0.20 ms per token,  4936.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =   49399.75 ms /   705 tokens (   70.07 ms per token,    14.27 tokens per second)\n",
            "llama_print_timings:        eval time =  175730.54 ms /   567 runs   (  309.93 ms per token,     3.23 tokens per second)\n",
            "llama_print_timings:       total time =  225837.81 ms /  1272 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgTTq_4T0L33",
        "outputId": "7cdf7344-e32a-436f-fab3-30021dee3783"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Sure, I'd be happy to help you with that! Here are my evaluations of each proposed solution:\n",
            "1. Risk Appetite: Pros - A clear and well-defined risk appetite aligns with the business strategy and objectives, providing a framework for decision-making and risk management. Cons - A fixed risk appetite may not be adaptable to changing market conditions or unforeseen risks. Feasibility - High. Probability of success - High.\n",
            "2. Risk Culture: Pros - A strong risk culture encourages employees to speak up and report potential risks, promoting a proactive approach to risk management. Cons - A culture that prioritizes risk avoidance over risk management may lead to missed opportunities. Feasibility - High. Probability of success - High.\n",
            "3. Risk Governance: Pros - An effective risk governance structure provides clear roles and responsibilities for risk management across the organization. Cons - Over-centralization of risk governance may lead to inefficiencies and lack of agility. Feasibility - High. Probability of success - High.\n",
            "4. Compliance: Pros - A high priority on compliance ensures adherence to relevant laws and regulations, reducing the likelihood of legal or regulatory penalties. Cons - Over-emphasis on compliance may lead to a lack of innovation and competitiveness. Feasibility - High. Probability of success - Moderate.\n",
            "5. Risk Mitigation: Pros - Diversification of the investment portfolio and the creation of Group Risk Management can help minimize potential risks. Cons - No silver bullet for risk mitigation, as risks are inherent in any business. Feasibility - High. Probability of success - Moderate.\n",
            "6. Risk Identification: Pros - A robust risk identification process can help identify and assess potential risks early on. Cons - No guarantee that all risks will be identified, especially unexpected ones. Feasibility - High. Probability of success - Moderate.\n",
            "Overall, I would rate the feasibility and probability of success for each solution as follows:\n",
            "1-5: High\n",
            "6: Moderate to High\n",
            "Based on these evaluations, it seems that AXA has a solid foundation in place for risk management, with well-defined risk appetite, culture, governance, compliance, and identification processes. However, there is always room for improvement, and the company should continue to monitor and adapt its approach to risk management to stay ahead of potential risks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_template = \"\"\"\n",
        "For the following problem: {problem}, rank the solutions presented in the following evaluations: \\n{evaluations}\\n.\n",
        "Pick most promising solution and present implementation strategies and methods to handle potential obstacles for this solution.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Pf_rnkKJ0TiC"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response= lccp_llm(prompt=ranking_template,echo=False,temperature=0.5,top_p=.80,frequency_penalty=0,max_tokens=1500)"
      ],
      "metadata": {
        "id": "K0xZE6BV02ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "705e36a4-00fb-42bf-f0b8-622a42cd11b0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =   35527.80 ms\n",
            "llama_print_timings:      sample time =     107.40 ms /   566 runs   (    0.19 ms per token,  5270.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4096.77 ms /    52 tokens (   78.78 ms per token,    12.69 tokens per second)\n",
            "llama_print_timings:        eval time =  158498.04 ms /   565 runs   (  280.53 ms per token,     3.56 tokens per second)\n",
            "llama_print_timings:       total time =  163249.86 ms /   617 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Response with Tree-of-thought"
      ],
      "metadata": {
        "id": "4gYBXgxz3RaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_tree_reaponse=(response[\"choices\"][0][\"text\"])\n",
        "final_tree_reaponse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "11yWP9KI3LGj",
        "outputId": "e84520ef-cd52-4fd2-d87a-74c90841f752"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSolution 1: {solution 1}\\nStrengths: {strengths of solution 1}\\nWeaknesses: {weaknesses of solution 1}\\nPotential obstacles: {potential obstacles for solution 1}\\nImplementation strategies: {implementation strategies for solution 1}\\n\\nSolution 2: {solution 2}\\nStrengths: {strengths of solution 2}\\nWeaknesses: {weaknesses of solution 2}\\nPotential obstacles: {potential obstacles for solution 2}\\nImplementation strategies: {implementation strategies for solution 2}\\n\\nSolution 3: {solution 3}\\nStrengths: {strengths of solution 3}\\nWeaknesses: {weaknesses of solution 3}\\nPotential obstacles: {potential obstacles for solution 3}\\nImplementation strategies: {implementation strategies for solution 3}\\n\\nBased on the evaluations provided, I would rank the solutions as follows:\\nRanking:\\n1. Solution 1\\n2. Solution 3\\n3. Solution 2\\n\\nThe most promising solution is Solution 1, which has several strengths that make it a viable option for addressing the problem at hand. These strengths include:\\n* It leverages existing technologies and infrastructure, which can reduce costs and improve scalability.\\n* It provides a flexible and adaptive approach to managing the supply chain, allowing for real-time adjustments based on changing market conditions.\\n* It has the potential to improve forecast accuracy by leveraging machine learning algorithms and historical data.\\nHowever, Solution 1 also has some weaknesses that need to be addressed, such as the potential for bias in the machine learning models if the training data is not diverse enough. Additionally, there may be challenges in implementing this solution in a dynamic and fast-changing market environment.\\nTo handle these potential obstacles, I would recommend the following implementation strategies:\\n* Ensure that the machine learning algorithms are trained on a diverse dataset to minimize bias and improve accuracy.\\n* Implement real-time monitoring and adjustment mechanisms to allow for quick response to changing market conditions.\\n* Develop contingency plans to address unexpected disruptions or changes in the supply chain.\\nOverall, Solution 1 has the most promising combination of strengths and weaknesses, and with careful planning and execution, it can be a successful solution for managing the supply chain in a dynamic and fast-changing market environment.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rephrase & Respond\n",
        "- When generating a response, the model can create multiple possible outputs, each considered a \"choice.\" The most suitable choice is then selected to be presented to the user."
      ],
      "metadata": {
        "id": "HuSUW-iu8ICM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rephase_respond_template=\"\"\"\n",
        "context:\n",
        "{context}\n",
        "===\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "\n",
        "Observe the context presented above, rephrase and expand the above question to help you do better answering.\n",
        "Maintain all the information in the original question.\n",
        "Please note that you only have to rephrase the question, do not mention the context.\n",
        "The context is only presented for your reference.\n",
        "\n",
        "Present your answer in the following format:\n",
        "Rephrased Question:\n",
        "<rephrased-question-here>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "p2Fx-sPk3kT1"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### when do Rephrase & Respond is use full ?\n",
        "- When the initial response might be confusing or not as clear as it could be, rephrasing helps to ensure the message is easily understood.\n",
        "- When the response needs to be more formal or polished, rephrasing can adjust the tone and structure accordingly.\n",
        "- When the original response is too complex or technical, rephrasing can make it more accessible to a broader audience."
      ],
      "metadata": {
        "id": "03ZoAqEx9NE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rephase_response_prompt= llama_prompt_template.format(\n",
        "    system_message=system_message,\n",
        "    user_message= rephase_respond_template.format(\n",
        "        context=AXA_2000_context,\n",
        "        question=actual_question\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "XSpGoL1R9DYf"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rephase_response_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Z9UReG1AQhOD",
        "outputId": "1aaa69a2-c883-4ce5-8ea9-24c9c3d79b07"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[/s][INS]<<SYS>>\\nYou are an assistance you are answer a quary on a finacial information\\nDonot reapeat the question only answer the question presented by the user\\n<</SYS>>\\n\\ncontext:\\n\\nAs soon as he takes office, Henri de Castries chooses to sell off the US investment bank Donaldson, Lufkin & Jenrette (DLJ) and target operational excellence for the Group’s core business areas (insurance and asset management).\\n\\nThe Group organizes itself to weather this storm: rolling out a plan to reduce spending, turning around its technical results and further strengthening its risk management, with the creation of Group Risk Management which objective is to analyze the Group’s risk exposure and appetite with a more in-depth approach and to prepare for future new regulations (Solvency 2).\\n\\nIn 2006, the economic environment is positive again. AXA returns to profitable growth, acquires the Swiss firm Winterthur and starts investing in emerging markets.\\n\\nWhen the subprime financial crisis breaks out in summer 2007, AXA has learned the lessons from 2001. Thanks to its efficient internal risk management system (GRM), the Group is affected, but shows its resilience, without public bailouts.\\n\\nIn this volatile environment, AXA remains convinced of the importance of its long-term commitments to its customers and society in general. In line with this spirit, AXA launches the AXA Research Fund to improve the understanding and prevention of major risks around the world. The AXA Research Fund further enhances the wide range of initiatives in place across the Group, which is committed to taking action on what counts for communities. Created out of the belief that science has a key role to play in meeting society’s major challenges, AXA sets out its commitment to help drive collective progress by supporting research projects focused on health, the environment, new technologies and socioeconomics.\\n\\n===\\nQuestion:\\nWhen the subprime financial crisis breaks out? What the company had learned?\\n\\n\\nObserve the context presented above, rephrase and expand the above question to help you do better answering.\\nMaintain all the information in the original question.\\nPlease note that you only have to rephrase the question, do not mention the context.\\nThe context is only presented for your reference.\\n\\nPresent your answer in the following format:\\nRephrased Question:\\n<rephrased-question-here>\\n[/INST]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instial_response= lccp_llm(prompt=rephase_response_prompt,temperature=0.5,top_p=0.8,max_tokens=1500,echo=False)"
      ],
      "metadata": {
        "id": "tBed258y-tOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4750c4a-5579-4877-c738-04cf857cd012"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =   35527.80 ms\n",
            "llama_print_timings:      sample time =       7.94 ms /    42 runs   (    0.19 ms per token,  5288.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =   37722.26 ms /   572 tokens (   65.95 ms per token,    15.16 tokens per second)\n",
            "llama_print_timings:        eval time =   11998.39 ms /    41 runs   (  292.64 ms per token,     3.42 tokens per second)\n",
            "llama_print_timings:       total time =   49754.26 ms /   613 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rephrased_question = instial_response[\"choices\"][0][\"text\"].strip()"
      ],
      "metadata": {
        "id": "yghnnmc4-tMd"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rephrased_question)"
      ],
      "metadata": {
        "id": "ZdnN8c5l-tJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f12ae1a-ff41-41c0-9a56-bd282525abea"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rephrased Question: What lessons did AXA learn from the 2001 financial crisis that helped the company navigate through the subprime financial crisis of 2007?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rephrase_marker = rephrased_question.find('Rephrased Question:')"
      ],
      "metadata": {
        "id": "vNpjIHHs-tGu"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rephrased_question[rephrase_marker+19:])"
      ],
      "metadata": {
        "id": "PphCgVNY-tBQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca47d56e-39d9-49ef-a9e5-ebbc13f2c2bb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " What lessons did AXA learn from the 2001 financial crisis that helped the company navigate through the subprime financial crisis of 2007?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rephrased_factual_question = rephrased_question[rephrase_marker+19:]"
      ],
      "metadata": {
        "id": "_pA9gRp0-s-Z"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_template = \"\"\"\n",
        "Context:\n",
        "{context}\n",
        "===\n",
        "\n",
        "Original Question:\n",
        "{question}\n",
        "\n",
        "Rephrased Question:\n",
        "{rephrased_question}\n",
        "\n",
        "Given the above context, use your answer for the rephrased question presented above to answer the original question.\n",
        "Present your final answer in the following format.\n",
        "Final Answer: <your-final-answer>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "naexFyWF-s7A"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_prompt = llama_prompt_template.format(\n",
        "    system_message=system_message,\n",
        "    user_message=response_template.format(\n",
        "        context=AXA_2000_context,\n",
        "        question=actual_question,\n",
        "        rephrased_question=rephrased_factual_question\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "_UXfPbXpAPh9"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_prompt)"
      ],
      "metadata": {
        "id": "2Tw9csFnAPfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c87658d-9daf-4d96-84dd-3671cefb40f7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[/s][INS]<<SYS>>\n",
            "You are an assistance you are answer a quary on a finacial information\n",
            "Donot reapeat the question only answer the question presented by the user\n",
            "<</SYS>>\n",
            "\n",
            "Context:\n",
            "\n",
            "As soon as he takes office, Henri de Castries chooses to sell off the US investment bank Donaldson, Lufkin & Jenrette (DLJ) and target operational excellence for the Group’s core business areas (insurance and asset management).\n",
            "\n",
            "The Group organizes itself to weather this storm: rolling out a plan to reduce spending, turning around its technical results and further strengthening its risk management, with the creation of Group Risk Management which objective is to analyze the Group’s risk exposure and appetite with a more in-depth approach and to prepare for future new regulations (Solvency 2).\n",
            "\n",
            "In 2006, the economic environment is positive again. AXA returns to profitable growth, acquires the Swiss firm Winterthur and starts investing in emerging markets.\n",
            "\n",
            "When the subprime financial crisis breaks out in summer 2007, AXA has learned the lessons from 2001. Thanks to its efficient internal risk management system (GRM), the Group is affected, but shows its resilience, without public bailouts.\n",
            "\n",
            "In this volatile environment, AXA remains convinced of the importance of its long-term commitments to its customers and society in general. In line with this spirit, AXA launches the AXA Research Fund to improve the understanding and prevention of major risks around the world. The AXA Research Fund further enhances the wide range of initiatives in place across the Group, which is committed to taking action on what counts for communities. Created out of the belief that science has a key role to play in meeting society’s major challenges, AXA sets out its commitment to help drive collective progress by supporting research projects focused on health, the environment, new technologies and socioeconomics.\n",
            "\n",
            "===\n",
            "\n",
            "Original Question:\n",
            "When the subprime financial crisis breaks out? What the company had learned?\n",
            "\n",
            "Rephrased Question:\n",
            " What lessons did AXA learn from the 2001 financial crisis that helped the company navigate through the subprime financial crisis of 2007?\n",
            "\n",
            "Given the above context, use your answer for the rephrased question presented above to answer the original question.\n",
            "Present your final answer in the following format.\n",
            "Final Answer: <your-final-answer>\n",
            "[/INST]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_llama=lccp_llm(prompt=response_prompt,temperature=0.5,top_p=0.80,max_tokens=1500,echo=False)\n"
      ],
      "metadata": {
        "id": "wmYBUEzxAPcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "750310f6-81fe-48a9-f5cd-9894f2d2e24e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =   35527.80 ms\n",
            "llama_print_timings:      sample time =      14.26 ms /    73 runs   (    0.20 ms per token,  5117.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =   34268.63 ms /   518 tokens (   66.16 ms per token,    15.12 tokens per second)\n",
            "llama_print_timings:        eval time =   20435.37 ms /    72 runs   (  283.82 ms per token,     3.52 tokens per second)\n",
            "llama_print_timings:       total time =   54762.45 ms /   590 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_llama[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "tRcL8086APZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8abb958e-d027-453e-af81-a6ec73e6ddf5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Final Answer: In 2001, AXA learned the importance of efficient internal risk management systems (GRM) and the value of being resilient in the face of financial crises. These lessons were crucial in helping the company navigate through the subprime financial crisis of 2007 without public bailouts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Responce for Rephrase & Respond"
      ],
      "metadata": {
        "id": "U_1zl3nHOORQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rephase_response_llm=response_llama[\"choices\"][0][\"text\"].strip()\n",
        "rephase_response_llm"
      ],
      "metadata": {
        "id": "Uu2xpjjFAPXb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c0a0ca2f-f793-4384-b2d5-9956409d95d2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Final Answer: In 2001, AXA learned the importance of efficient internal risk management systems (GRM) and the value of being resilient in the face of financial crises. These lessons were crucial in helping the company navigate through the subprime financial crisis of 2007 without public bailouts.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain-of-Verification (CoVe)"
      ],
      "metadata": {
        "id": "QFjP0j64OiEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message =\"\"\"\n",
        "You are tasked to answer queries on financial information.\n",
        "Only answer the specific question presented by the user.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QvS2XR1WAPVN"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BaseLine response"
      ],
      "metadata": {
        "id": "HuRQBMVXOwUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_response=\"\"\"\n",
        "content:\n",
        "{content}\n",
        "===\n",
        "Use the above context to answer the following question:\n",
        "Question:\n",
        "{question}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "e7-oNRHpAPSm"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baselinemodel= llama_prompt_template.format(\n",
        "    system_message=system_message,\n",
        "    user_message=baseline_response.format(\n",
        "        content=AXA_2000_context,\n",
        "        question=actual_question\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "hsV59S-CAPQQ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(baselinemodel)"
      ],
      "metadata": {
        "id": "te2cHBMDAPNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302662f9-b8d2-4649-bf0f-5fe77874dcd6"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[/s][INS]<<SYS>>\n",
            "\n",
            "You are tasked to answer queries on financial information.\n",
            "Only answer the specific question presented by the user.\n",
            "\n",
            "<</SYS>>\n",
            "\n",
            "content:\n",
            "\n",
            "As soon as he takes office, Henri de Castries chooses to sell off the US investment bank Donaldson, Lufkin & Jenrette (DLJ) and target operational excellence for the Group’s core business areas (insurance and asset management).\n",
            "\n",
            "The Group organizes itself to weather this storm: rolling out a plan to reduce spending, turning around its technical results and further strengthening its risk management, with the creation of Group Risk Management which objective is to analyze the Group’s risk exposure and appetite with a more in-depth approach and to prepare for future new regulations (Solvency 2).\n",
            "\n",
            "In 2006, the economic environment is positive again. AXA returns to profitable growth, acquires the Swiss firm Winterthur and starts investing in emerging markets.\n",
            "\n",
            "When the subprime financial crisis breaks out in summer 2007, AXA has learned the lessons from 2001. Thanks to its efficient internal risk management system (GRM), the Group is affected, but shows its resilience, without public bailouts.\n",
            "\n",
            "In this volatile environment, AXA remains convinced of the importance of its long-term commitments to its customers and society in general. In line with this spirit, AXA launches the AXA Research Fund to improve the understanding and prevention of major risks around the world. The AXA Research Fund further enhances the wide range of initiatives in place across the Group, which is committed to taking action on what counts for communities. Created out of the belief that science has a key role to play in meeting society’s major challenges, AXA sets out its commitment to help drive collective progress by supporting research projects focused on health, the environment, new technologies and socioeconomics.\n",
            "\n",
            "===\n",
            "Use the above context to answer the following question:\n",
            "Question:\n",
            "When the subprime financial crisis breaks out? What the company had learned?\n",
            "[/INST]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=lccp_llm(prompt=baselinemodel,max_tokens=1500,temperature=0.5,top_p=0.80,)"
      ],
      "metadata": {
        "id": "TJRBVnS1APLC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b9cd6b6-134d-47ee-e30b-e0484667b0ab"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =   35527.80 ms\n",
            "llama_print_timings:      sample time =      14.49 ms /    75 runs   (    0.19 ms per token,  5176.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =   30413.34 ms /   469 tokens (   64.85 ms per token,    15.42 tokens per second)\n",
            "llama_print_timings:        eval time =   20937.92 ms /    74 runs   (  282.94 ms per token,     3.53 tokens per second)\n",
            "llama_print_timings:       total time =   51413.24 ms /   543 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_response=response[\"choices\"][0][\"text\"]\n",
        "baseline_response"
      ],
      "metadata": {
        "id": "imIxGT3dAPIs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "49084650-b0be-40be-81d4-d054505ae140"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  According to the text, the subprime financial crisis broke out in summer 2007. As a result of this crisis, AXA had learned the lessons from its previous experience in 2001, including the importance of efficient internal risk management systems (GRM) and the resilience of the company without public bailouts.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Verification questions"
      ],
      "metadata": {
        "id": "n-305rYRRlgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "verifications_prompt_template = \"\"\"\n",
        "Your task is to create verification questions based on the below original question and the baseline response.\n",
        "The verification questions are meant for verifying the factual acuracy in the baseline response.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "===\n",
        "\n",
        "Question:\n",
        "Use the above context to answer the following question: {question}\n",
        "\n",
        "Baseline Response:\n",
        "{baseline_response}\n",
        "\n",
        "Respond with your verification questions in a JSON format with the following headers.\n",
        "```JSON\n",
        "question1: <verification-question-1>\n",
        "question2: <veriification-question-2>\n",
        "and so on.\n",
        "```\n",
        "Do not provide answers to these verification questions. Respond only with the JSON.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NVMG837mAPGI"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verification_prompt= llama_prompt_template.format(\n",
        "    system_message=system_message,\n",
        "    user_message=verifications_prompt_template.format(\n",
        "        context=AXA_2000_context,\n",
        "        question=actual_question,\n",
        "        baseline_response=baseline_response,\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "yjSe2wghRsIs"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(verification_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G3G3X0TSg1V",
        "outputId": "a33f458c-2bd4-4f06-b118-a125166aefac"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[/s][INS]<<SYS>>\n",
            "\n",
            "You are tasked to answer queries on financial information.\n",
            "Only answer the specific question presented by the user.\n",
            "\n",
            "<</SYS>>\n",
            "\n",
            "Your task is to create verification questions based on the below original question and the baseline response.\n",
            "The verification questions are meant for verifying the factual acuracy in the baseline response.\n",
            "\n",
            "Context:\n",
            "\n",
            "As soon as he takes office, Henri de Castries chooses to sell off the US investment bank Donaldson, Lufkin & Jenrette (DLJ) and target operational excellence for the Group’s core business areas (insurance and asset management).\n",
            "\n",
            "The Group organizes itself to weather this storm: rolling out a plan to reduce spending, turning around its technical results and further strengthening its risk management, with the creation of Group Risk Management which objective is to analyze the Group’s risk exposure and appetite with a more in-depth approach and to prepare for future new regulations (Solvency 2).\n",
            "\n",
            "In 2006, the economic environment is positive again. AXA returns to profitable growth, acquires the Swiss firm Winterthur and starts investing in emerging markets.\n",
            "\n",
            "When the subprime financial crisis breaks out in summer 2007, AXA has learned the lessons from 2001. Thanks to its efficient internal risk management system (GRM), the Group is affected, but shows its resilience, without public bailouts.\n",
            "\n",
            "In this volatile environment, AXA remains convinced of the importance of its long-term commitments to its customers and society in general. In line with this spirit, AXA launches the AXA Research Fund to improve the understanding and prevention of major risks around the world. The AXA Research Fund further enhances the wide range of initiatives in place across the Group, which is committed to taking action on what counts for communities. Created out of the belief that science has a key role to play in meeting society’s major challenges, AXA sets out its commitment to help drive collective progress by supporting research projects focused on health, the environment, new technologies and socioeconomics.\n",
            "\n",
            "===\n",
            "\n",
            "Question:\n",
            "Use the above context to answer the following question: When the subprime financial crisis breaks out? What the company had learned?\n",
            "\n",
            "Baseline Response:\n",
            "  According to the text, the subprime financial crisis broke out in summer 2007. As a result of this crisis, AXA had learned the lessons from its previous experience in 2001, including the importance of efficient internal risk management systems (GRM) and the resilience of the company without public bailouts.\n",
            "\n",
            "Respond with your verification questions in a JSON format with the following headers.\n",
            "```JSON\n",
            "question1: <verification-question-1>\n",
            "question2: <veriification-question-2>\n",
            "and so on.\n",
            "```\n",
            "Do not provide answers to these verification questions. Respond only with the JSON.\n",
            "[/INST]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verification_response= lccp_llm(prompt=verification_prompt,max_tokens=1500,echo=False,repeat_penalty=1.0,temperature=0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_gZa_HcR8xw",
        "outputId": "6f1895ed-8a96-4e3a-b09c-4e261ab072f1"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =   35527.80 ms\n",
            "llama_print_timings:      sample time =       7.83 ms /   183 runs   (    0.04 ms per token, 23356.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =   52954.37 ms /   183 runs   (  289.37 ms per token,     3.46 tokens per second)\n",
            "llama_print_timings:       total time =   53089.44 ms /   183 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(verification_response[\"choices\"][0][\"text\"].strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SOeJsa0SVMT",
        "outputId": "b1e5b36e-2d39-48a4-8975-53b1a23415b4"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "\"question1\": \"Can you provide more details on what specific lessons AXA learned from its previous experience in 2001?\",\n",
            "\"question2\": \"How did AXA's efficient internal risk management system (GRM) help the company during the subprime financial crisis?\",\n",
            "\"question3\": \"What were some of the specific actions taken by AXA to show resilience during the crisis without public bailouts?\",\n",
            "\"question4\": \"Can you provide examples of the types of research projects supported by the AXA Research Fund to improve the understanding and prevention of major risks around the world?\",\n",
            "\"question5\": \"How did AXA's commitment to taking action on what counts for communities align with its long-term commitments to its customers and society in general?\",\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verification_factual_question=verification_response[\"choices\"][0][\"text\"].strip()\n",
        "print(verification_factual_question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly28DCnjSbuL",
        "outputId": "740f9fa0-8c14-4fd5-bfd8-4a6e9a84662e"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "\"question1\": \"Can you provide more details on what specific lessons AXA learned from its previous experience in 2001?\",\n",
            "\"question2\": \"How did AXA's efficient internal risk management system (GRM) help the company during the subprime financial crisis?\",\n",
            "\"question3\": \"What were some of the specific actions taken by AXA to show resilience during the crisis without public bailouts?\",\n",
            "\"question4\": \"Can you provide examples of the types of research projects supported by the AXA Research Fund to improve the understanding and prevention of major risks around the world?\",\n",
            "\"question5\": \"How did AXA's commitment to taking action on what counts for communities align with its long-term commitments to its customers and society in general?\",\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verification_responses_template = \"\"\"Answer the following question correctly based on the context given below:\n",
        "Context:\n",
        "{context}\n",
        "===\n",
        "\n",
        "Question: {verification_question}\"\"\""
      ],
      "metadata": {
        "id": "NIZM-j-VTDxS"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "verification_question_beginning = verification_responses_template.find(\"{\")\n",
        "verification_factual_questions_dict = (verification_responses_template[verification_question_beginning:])"
      ],
      "metadata": {
        "id": "3g8oE-UwTj5D"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(verification_factual_questions_dict)\n",
        "\n",
        "verification_responses = []\n",
        "verification_factual_questions_dict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "mz_S7r4STj0Y",
        "outputId": "cbb81b35-be73-42c0-d6ae-a6c24f7f2af0"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{context}\n",
            "===\n",
            "\n",
            "Question: {verification_question}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{context}\\n===\\n\\nQuestion: {verification_question}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for verification_factual_question in verification_factual_questions_dict.values():\n",
        "\n",
        "    verification_prompt_response = llama_prompt_template.format(\n",
        "        system_message=system_message,\n",
        "        user_message=verification_responses_template.format(\n",
        "            context=AXA_2000_context,\n",
        "            verification_question=verification_factual_question\n",
        "        )\n",
        "    )\n",
        "\n",
        "    response = lccp_llm(\n",
        "        prompt=verification_prompt,\n",
        "        max_tokens=1024,\n",
        "        temperature=0,\n",
        "        top_p=0.95,\n",
        "        repeat_penalty=1.2,\n",
        "        echo=False # do not return the prompt\n",
        "    )\n",
        "\n",
        "    verification_responses.append(response[\"choices\"][0][\"text\"].strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "otXVU4uxTju6",
        "outputId": "4ae974cb-6a42-4a6d-c7b4-8939a8d6791f"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'values'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-133-9df2ad18f68f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mverification_factual_question\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mverification_factual_questions_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     verification_prompt_response = llama_prompt_template.format(\n\u001b[1;32m      4\u001b[0m         \u001b[0msystem_message\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msystem_message\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         user_message=verification_responses_template.format(\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'values'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gNwprEQLTjsU"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verification_prompt= llama_prompt_template.format(\n",
        "    system_message=system_message,\n",
        "    user_message=verification_responses_template.format(\n",
        "        context=AXA_2000_context,\n",
        "        verification_question=actual_question,\n",
        "        baseline_response=baseline_response,\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "N-MmRQMMTRoQ"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eYDt6sguUXRu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}